{
  "provider": "Anthropic",
  "model": "Claude 4.5 Opus",
  "date": "11-24-2025",
  "url": "https://assets.anthropic.com/m/64823ba7485345a7/Claude-Opus-4-5-System-Card.pdf",
  "benchmarkResults": [
    {
      "name": "SWE-bench Verified (no thinking)",
      "score": "80.9%"
    },
    {
      "name": "Terminal-bench 2.0 (128k thinking budget)",
      "score": "59.3%"
    },
    {
      "name": "Terminal-bench 2.0 (64k thinking budget)",
      "score": "57.8%"
    },
    {
      "name": "τ²-Bench (Retail, no thinking)",
      "score": "88.9%"
    },
    {
      "name": "τ²-Bench (Telecom, no thinking)",
      "score": "98.2%"
    },
    {
      "name": "τ²-Bench (Airline, original)",
      "score": "70.1%"
    },
    {
      "name": "τ²-Bench (Airline, corrected)",
      "score": "87.8%"
    },
    {
      "name": "MCP Atlas (no thinking)",
      "score": "62.3%"
    },
    {
      "name": "OSWorld (64k thinking budget)",
      "score": "66.3%"
    },
    {
      "name": "ARC-AGI-1 (Private)",
      "score": "80.0%"
    },
    {
      "name": "ARC-AGI-2 (Verified, 64k thinking budget)",
      "score": "37.6%"
    },
    {
      "name": "GPQA Diamond (64k thinking budget)",
      "score": "87.0%"
    },
    {
      "name": "MMMU (validation, 64k thinking budget)",
      "score": "80.7%"
    },
    {
      "name": "MMMLU (64k thinking budget)",
      "score": "90.8%"
    },
    {
      "name": "SWE-bench Pro (no thinking)",
      "score": "52.0%"
    },
    {
      "name": "SWE-bench Pro (64k thinking budget)",
      "score": "51.6%"
    },
    {
      "name": "SWE-bench Multilingual",
      "score": "76.2%"
    },
    {
      "name": "BrowseComp-Plus (with tool result clearing)",
      "score": "67.59%"
    },
    {
      "name": "BrowseComp-Plus (with tool result clearing + memory)",
      "score": "72.89%"
    },
    {
      "name": "Multi-agent search (Opus 4.5 orchestrator + Haiku 4.5 subagents)",
      "score": "87.0%"
    },
    {
      "name": "Multi-agent search (Opus 4.5 orchestrator + Sonnet 4.5 subagents)",
      "score": "85.4%"
    },
    {
      "name": "Multi-agent search (Opus 4.5 orchestrator + Opus 4.5 subagents)",
      "score": "92.3%"
    },
    {
      "name": "Multi-agent search (Single-agent baseline)",
      "score": "74.8%"
    },
    {
      "name": "Vending-Bench 2 (Final balance)",
      "score": "$4,967.06"
    },
    {
      "name": "FinanceAgent (External analysis by Vals AI, 64k thinking)",
      "score": "55.2%"
    },
    {
      "name": "FinanceAgent (Internal testing, 64k thinking)",
      "score": "61.07%"
    },
    {
      "name": "FinanceAgent (Internal testing, 64k thinking, 1M context)",
      "score": "61.03%"
    },
    {
      "name": "CyberGym (pass@1)",
      "score": "50.63%"
    },
    {
      "name": "SpreadsheetBench",
      "score": "64.25%"
    },
    {
      "name": "Humanity's Last Exam (Reasoning-only)",
      "score": "51.9%"
    },
    {
      "name": "Humanity's Last Exam (Tools-only: web search, web fetch, code execution)",
      "score": "68.3%"
    },
    {
      "name": "AIME 2025 (no tools, 64k thinking)",
      "score": "92.77%"
    },
    {
      "name": "AIME 2025 (with python tools, 64k thinking)",
      "score": "100%"
    },
    {
      "name": "LAB-Bench FigQA (without tools and no thinking)",
      "score": "54.9%"
    },
    {
      "name": "LAB-Bench FigQA (image cropping tool + 32,768 thinking tokens)",
      "score": "69.2%"
    },
    {
      "name": "WebArena (Single policy model, general prompts)",
      "score": "65.3%"
    },
    {
      "name": "WebArena (Pass@2)",
      "score": "69.5%"
    },
    {
      "name": "WebArena (Pass@3)",
      "score": "71.2%"
    },
    {
      "name": "WebArena (Pass@4)",
      "score": "72.4%"
    },
    {
      "name": "100Q-Hard (Correct rate, 16k thinking budget)",
      "score": "81.3%"
    },
    {
      "name": "Simple-QA Verified (Correct rate, no thinking)",
      "score": "37.9%"
    },
    {
      "name": "Simple-QA Verified (Correct rate, 16k thinking budget)",
      "score": "48.9%"
    },
    {
      "name": "AA-Omniscience (Correct rate, no thinking)",
      "score": "53.8%"
    },
    {
      "name": "AA-Omniscience (Correct rate, 16k thinking budget)",
      "score": "62.0%"
    },
    {
      "name": "Agentic coding (Refusal rate)",
      "score": "100%"
    },
    {
      "name": "Claude Code (Malicious refusal rate, no mitigations)",
      "score": "77.80%"
    },
    {
      "name": "Claude Code (Dual-use & Benign success rate, no mitigations)",
      "score": "93.07%"
    },
    {
      "name": "Claude Code (Malicious refusal rate, with mitigations)",
      "score": "97.35%"
    },
    {
      "name": "Claude Code (Dual-use & Benign success rate, with mitigations)",
      "score": "96.52%"
    },
    {
      "name": "Malicious computer use (Refusal rate)",
      "score": "88.39%"
    },
    {
      "name": "Gray Swan ART (Indirect prompt injection, k=1)",
      "score": "0.1%"
    },
    {
      "name": "Gray Swan ART (Indirect prompt injection, k=10)",
      "score": "0.4%"
    },
    {
      "name": "Gray Swan ART (Indirect prompt injection, k=100)",
      "score": "2.1%"
    },
    {
      "name": "Gray Swan ART (Total: direct + indirect + jailbreaking, k=1)",
      "score": "1.8%"
    },
    {
      "name": "Gray Swan ART (Total: direct + indirect + jailbreaking, k=100)",
      "score": "11.4%"
    },
    {
      "name": "Shade coding ASR (Standard thinking, 1 attempt)",
      "score": "0.7%"
    },
    {
      "name": "Shade coding ASR (Extended thinking, 1 attempt)",
      "score": "0.3%"
    },
    {
      "name": "Shade computer use ASR (Standard thinking, 1 attempt)",
      "score": "0.71%"
    },
    {
      "name": "Shade computer use ASR (Extended thinking, 1 attempt)",
      "score": "0.0%"
    },
    {
      "name": "CBRN Long-form virology task 1 (max of 5)",
      "score": "0.845"
    },
    {
      "name": "CBRN Long-form virology task 2 (pass@5)",
      "score": "0.912"
    },
    {
      "name": "CBRN Multimodal virology (VMQA/VCT, mean score)",
      "score": "0.4771"
    },
    {
      "name": "CBRN LAB-Bench ProtocolQA",
      "score": "0.907"
    },
    {
      "name": "CBRN LAB-Bench Cloning Scenarios",
      "score": "0.758"
    },
    {
      "name": "CBRN LAB-Bench SeqQA",
      "score": "0.8517"
    },
    {
      "name": "CBRN Creative biology",
      "score": "0.524"
    },
    {
      "name": "CBRN Bioinformatics",
      "score": "0.737"
    },
    {
      "name": "Autonomy Kernels task (best speedup)",
      "score": "252.42x"
    },
    {
      "name": "Autonomy Time series forecasting (MSE easy)",
      "score": "5.66"
    },
    {
      "name": "Autonomy Text-based RL task (best score)",
      "score": "0.975"
    },
    {
      "name": "Autonomy LLM training (best speedup)",
      "score": "16.53x"
    },
    {
      "name": "Autonomy Quadruped RL (best score)",
      "score": "19.48"
    },
    {
      "name": "Autonomy Novel compiler (basic tests)",
      "score": "93.7%"
    },
    {
      "name": "Autonomy Novel compiler (complex tests)",
      "score": "69.37%"
    },
    {
      "name": "Internal AI Research Evaluation Suite 2",
      "score": "0.604"
    },
    {
      "name": "Cybench (pass@1)",
      "score": "0.82"
    }
  ],
  "notes": "The results reported are for Claude 4.5 Opus (often referred to as Claude Opus 4.5 in the document). Scores vary by the 'effort' parameter and 'extended thinking' budget. Unless otherwise noted, scores reflect the highest achieving configuration or the default 'high' effort. ARC-AGI scores are reported on private validation sets. SWE-bench Verified hard subset is a custom subset of 45 problems used for autonomy rule-out evaluations. ASL thresholds relate to Anthropic's Responsible Scaling Policy."
}
