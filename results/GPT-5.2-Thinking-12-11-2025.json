{
  "provider": "OpenAI",
  "model": "GPT-5.2 Thinking",
  "date": "12-11-2025",
  "urls": [
    "https://cdn.openai.com/pdf/3a4153c8-c748-4b71-8e31-aecbde944f8d/oai_5_2_system-card.pdf",
    "https://openai.com/index/introducing-gpt-5-2/"
  ],
  "benchmarkResults": [
    {
      "name": "Production Benchmarks (illicit) - not_unsafe",
      "score": "0.953"
    },
    {
      "name": "Production Benchmarks (personal data) - not_unsafe",
      "score": "0.966"
    },
    {
      "name": "Production Benchmarks (harassment) - not_unsafe",
      "score": "0.859"
    },
    {
      "name": "Production Benchmarks (sexual) - not_unsafe",
      "score": "0.940"
    },
    {
      "name": "Production Benchmarks (extremism) - not_unsafe",
      "score": "1.000"
    },
    {
      "name": "Production Benchmarks (hate) - not_unsafe",
      "score": "0.923"
    },
    {
      "name": "Production Benchmarks (self-harm) - not_unsafe",
      "score": "0.963"
    },
    {
      "name": "Production Benchmarks (violence) - not_unsafe",
      "score": "0.953"
    },
    {
      "name": "Production Benchmarks (sexual/minors) - not_unsafe",
      "score": "0.970"
    },
    {
      "name": "Production Benchmarks (mental health) - not_unsafe",
      "score": "0.915"
    },
    {
      "name": "Production Benchmarks (emotional reliance) - not_unsafe",
      "score": "0.955"
    },
    {
      "name": "StrongReject filtered (not_unsafe)",
      "score": "0.975"
    },
    {
      "name": "Prompt Injection (Agent JSK)",
      "score": "0.978"
    },
    {
      "name": "Prompt Injection (PlugInject)",
      "score": "0.996"
    },
    {
      "name": "Image input evaluations (hate) - not_unsafe",
      "score": "0.988"
    },
    {
      "name": "Image input evaluations (extremism) - not_unsafe",
      "score": "0.986"
    },
    {
      "name": "Image input evaluations (illicit) - not_unsafe",
      "score": "1.000"
    },
    {
      "name": "Image input evaluations (attack planning) - not_unsafe",
      "score": "1.000"
    },
    {
      "name": "Image input evaluations (self-harm) - not_unsafe",
      "score": "0.941"
    },
    {
      "name": "Image input evaluations (harms-erotic) - not_unsafe",
      "score": "0.990"
    },
    {
      "name": "Average Hallucination Rate - Browsing Enabled (% incorrect claims)",
      "score": "0.8%"
    },
    {
      "name": "Average Hallucination Rate - Browsing Enabled (% responses with 1+ major incorrect claims)",
      "score": "5.8%"
    },
    {
      "name": "Average Hallucination Rate - Browsing Disabled (% incorrect claims)",
      "score": "3.1%"
    },
    {
      "name": "Average Hallucination Rate - Browsing Disabled (% responses with 1+ major incorrect claims)",
      "score": "10.9%"
    },
    {
      "name": "Hallucination Rate by Domain - Browsing Enabled (Business + Marketing Research)",
      "score": "0.7%"
    },
    {
      "name": "Hallucination Rate by Domain - Browsing Enabled (Financial and Tax)",
      "score": "1.0%"
    },
    {
      "name": "Hallucination Rate by Domain - Browsing Enabled (Legal and Regulatory)",
      "score": "0.5%"
    },
    {
      "name": "Hallucination Rate by Domain - Browsing Enabled (Academic Essays)",
      "score": "0.3%"
    },
    {
      "name": "Hallucination Rate by Domain - Browsing Enabled (Current Events and News)",
      "score": "0.8%"
    },
    {
      "name": "Hallucination Rate by Domain - Browsing Disabled (Business + Marketing Research)",
      "score": "2.1%"
    },
    {
      "name": "Hallucination Rate by Domain - Browsing Disabled (Financial and Tax)",
      "score": "2.3%"
    },
    {
      "name": "Hallucination Rate by Domain - Browsing Disabled (Legal and Regulatory)",
      "score": "2.2%"
    },
    {
      "name": "Hallucination Rate by Domain - Browsing Disabled (Academic Essays)",
      "score": "0.5%"
    },
    {
      "name": "Hallucination Rate by Domain - Browsing Disabled (Current Events and News)",
      "score": "2.9%"
    },
    {
      "name": "HealthBench",
      "score": "0.633379"
    },
    {
      "name": "HealthBench Hard",
      "score": "0.420389"
    },
    {
      "name": "HealthBench Consensus",
      "score": "0.945020"
    },
    {
      "name": "Deception rate (Production traffic)",
      "score": "1.6%"
    },
    {
      "name": "Deception rate (Production Deception - Adversarial)",
      "score": "5.4%"
    },
    {
      "name": "Deception rate (CharXiv Missing Image - Strict output requirements)",
      "score": "88.8%"
    },
    {
      "name": "Deception rate (CharXiv Missing Image - Lenient output requirements)",
      "score": "54%"
    },
    {
      "name": "Deception rate (Browsing Broken Tools)",
      "score": "9.1%"
    },
    {
      "name": "Deception rate (Coding Deception)",
      "score": "25.6%"
    },
    {
      "name": "Cyber safety (Production traffic) - policy compliance rate",
      "score": "0.966"
    },
    {
      "name": "Cyber safety (Synthetic data) - policy compliance rate",
      "score": "0.993"
    },
    {
      "name": "MMLU Language (Arabic, 0-shot)",
      "score": "0.901"
    },
    {
      "name": "MMLU Language (Bengali, 0-shot)",
      "score": "0.889"
    },
    {
      "name": "MMLU Language (Chinese, 0-shot)",
      "score": "0.901"
    },
    {
      "name": "MMLU Language (French, 0-shot)",
      "score": "0.899"
    },
    {
      "name": "MMLU Language (German, 0-shot)",
      "score": "0.903"
    },
    {
      "name": "MMLU Language (Hindi, 0-shot)",
      "score": "0.900"
    },
    {
      "name": "MMLU Language (Indonesian, 0-shot)",
      "score": "0.904"
    },
    {
      "name": "MMLU Language (Italian, 0-shot)",
      "score": "0.910"
    },
    {
      "name": "MMLU Language (Japanese, 0-shot)",
      "score": "0.897"
    },
    {
      "name": "MMLU Language (Korean, 0-shot)",
      "score": "0.895"
    },
    {
      "name": "MMLU Language (Portuguese, 0-shot)",
      "score": "0.910"
    },
    {
      "name": "MMLU Language (Spanish, 0-shot)",
      "score": "0.913"
    },
    {
      "name": "MMLU Language (Swahili, 0-shot)",
      "score": "0.880"
    },
    {
      "name": "MMLU Language (Yoruba, 0-shot)",
      "score": "0.808"
    },
    {
      "name": "First-person fairness evaluation (harm_overall)",
      "score": "0.00997"
    },
    {
      "name": "Multimodal Troubleshooting Virology (pass@1, with browsing)",
      "score": "43%"
    },
    {
      "name": "ProtocolQA Open-Ended (pass@1, with browsing)",
      "score": "40%"
    },
    {
      "name": "Biorisk Tacit Knowledge and Troubleshooting (coms@32, with browsing)",
      "score": "48%"
    },
    {
      "name": "Biorisk Tacit Knowledge and Troubleshooting (refusals treated as passes)",
      "score": "83.33%"
    },
    {
      "name": "TroubleshootingBench (pass@1, with browsing)",
      "score": "35%"
    },
    {
      "name": "Professional CTFs (pass@12, no browsing)",
      "score": "82%"
    },
    {
      "name": "CVE-Bench blind 0day (pass@1, no browsing)",
      "score": "69%"
    },
    {
      "name": "Cyber Range (Simple Privilege Escalation)",
      "score": "PASS"
    },
    {
      "name": "Cyber Range (Basic Command and Control (C2))",
      "score": "PASS"
    },
    {
      "name": "Cyber Range (Azure SSRF)",
      "score": "PASS"
    },
    {
      "name": "Cyber Range (Taint Shared Content)",
      "score": "PASS"
    },
    {
      "name": "Cyber Range (Online Retailer)",
      "score": "PASS"
    },
    {
      "name": "Cyber Range (Coffee Roasters)",
      "score": "PASS"
    },
    {
      "name": "Cyber Range (Financial Capital)",
      "score": "FAIL"
    },
    {
      "name": "Cyber Range (Leaked Token)",
      "score": "FAIL"
    },
    {
      "name": "Cyber Range (Medium Command and Control (C2))",
      "score": "FAIL"
    },
    {
      "name": "Irregular External Eval (Vulnerability Research and Exploitation success rate)",
      "score": "83%"
    },
    {
      "name": "Irregular External Eval (Network Attack Simulation success rate)",
      "score": "100%"
    },
    {
      "name": "Irregular External Eval (Evasion success rate)",
      "score": "73%"
    },
    {
      "name": "Irregular External Eval (Vulnerability Research and Exploitation cost-per-success)",
      "score": "$10.8"
    },
    {
      "name": "Irregular External Eval (Network Attack Simulation cost-per-success)",
      "score": "$3.7"
    },
    {
      "name": "Irregular External Eval (Evasion cost-per-success)",
      "score": "$12.9"
    },
    {
      "name": "OpenAI PRs (pass@1, no browsing)",
      "score": "55%"
    },
    {
      "name": "MLE-Bench-30 (pass@1, no browsing)",
      "score": "16%"
    },
    {
      "name": "PaperBench (pass@1, no browsing)",
      "score": "39%"
    },
    {
      "name": "OpenAI-Proof Q&A / OPQA (pass@1, no browsing)",
      "score": "3%"
    },
    {
      "name": "GDPval (wins or ties vs human experts, reasoning effort xhigh)",
      "score": "70.9%"
    },
    {
      "name": "GDPval (clear wins vs human experts, reasoning effort xhigh)",
      "score": "49.8%"
    },
    {
      "name": "GDPval (no ties, reasoning effort xhigh)",
      "score": "61.0%"
    },
    {
      "name": "Investment banking spreadsheet tasks (internal, reasoning effort heavy)",
      "score": "68.4%"
    },
    {
      "name": "SWE-Bench Pro, Public (xhigh effort)",
      "score": "55.6%"
    },
    {
      "name": "SWE-bench Verified",
      "score": "80.0%"
    },
    {
      "name": "SWE-Lancer, IC Diamond",
      "score": "74.6%"
    },
    {
      "name": "ChatGPT answers without errors (with search)",
      "score": "93.9%"
    },
    {
      "name": "ChatGPT answers without errors (no search)",
      "score": "88.0%"
    },
    {
      "name": "Responses with at least one error (de-identified ChatGPT queries)",
      "score": "6.2%"
    },
    {
      "name": "OpenAI MRCRv2, 8 needles (4k-8k tokens)",
      "score": "98.2%"
    },
    {
      "name": "OpenAI MRCRv2, 8 needles (8k-16k tokens)",
      "score": "89.3%"
    },
    {
      "name": "OpenAI MRCRv2, 8 needles (16k-32k tokens)",
      "score": "95.3%"
    },
    {
      "name": "OpenAI MRCRv2, 8 needles (32k-64k tokens)",
      "score": "92.0%"
    },
    {
      "name": "OpenAI MRCRv2, 8 needles (64k-128k tokens)",
      "score": "85.6%"
    },
    {
      "name": "OpenAI MRCRv2, 8 needles (128k-256k tokens)",
      "score": "77.0%"
    },
    {
      "name": "BrowseComp Long Context 128k",
      "score": "92.0%"
    },
    {
      "name": "BrowseComp Long Context 256k",
      "score": "89.8%"
    },
    {
      "name": "GraphWalks bfs <128k",
      "score": "94.0%"
    },
    {
      "name": "Graphwalks parents <128k",
      "score": "89.0%"
    },
    {
      "name": "CharXiv reasoning (no tools)",
      "score": "82.1%"
    },
    {
      "name": "CharXiv reasoning (with Python)",
      "score": "88.7%"
    },
    {
      "name": "MMMU Pro (no tools)",
      "score": "79.5%"
    },
    {
      "name": "MMMU Pro (with Python)",
      "score": "80.4%"
    },
    {
      "name": "Video MMMU (no tools)",
      "score": "85.9%"
    },
    {
      "name": "Screenspot Pro (with Python)",
      "score": "86.3%"
    },
    {
      "name": "Tau2-bench Telecom (xhigh reasoning effort)",
      "score": "98.7%"
    },
    {
      "name": "Tau2-bench Telecom (no reasoning effort)",
      "score": "57.2%"
    },
    {
      "name": "Tau2-bench Retail (xhigh reasoning effort)",
      "score": "82.0%"
    },
    {
      "name": "Tau2-bench Retail (no reasoning effort)",
      "score": "77.6%"
    },
    {
      "name": "BrowseComp (tool usage accuracy)",
      "score": "65.8%"
    },
    {
      "name": "Scale MCP-Atlas",
      "score": "60.6%"
    },
    {
      "name": "Toolathlon",
      "score": "46.3%"
    },
    {
      "name": "GPQA Diamond (no tools)",
      "score": "92.4%"
    },
    {
      "name": "HLE (no tools)",
      "score": "34.5%"
    },
    {
      "name": "HLE (with search, Python)",
      "score": "45.5%"
    },
    {
      "name": "MMMLU",
      "score": "89.6%"
    },
    {
      "name": "HMMT, Feb 2025 (no tools)",
      "score": "99.4%"
    },
    {
      "name": "AIME 2025 (no tools)",
      "score": "100.0%"
    },
    {
      "name": "FrontierMath Tier 1-3 (with Python)",
      "score": "40.3%"
    },
    {
      "name": "FrontierMath Tier 4 (with Python)",
      "score": "14.6%"
    },
    {
      "name": "ARC-AGI-1 (Verified)",
      "score": "86.2%"
    },
    {
      "name": "ARC-AGI-2 (Verified)",
      "score": "52.9%"
    }
  ],
  "notes": "Results for GPT-5.2 refer primarily to GPT-5.2 Thinking (the reasoning model) and GPT-5.2 Instant (the non-reasoning model). Values for safety, preparedness, and agentic benchmarks generally correspond to GPT-5.2 Thinking with high or maximum (xhigh) reasoning effort and relevant tools (Browsing, Python) enabled as specified. GDPval win rates are measured against expert human judges. The blog Appendix also notes GPT-5.2 Pro variant scores for certain benchmarks like GPQA Diamond (93.2%) and ARC-AGI-1 (90.5%)."
}